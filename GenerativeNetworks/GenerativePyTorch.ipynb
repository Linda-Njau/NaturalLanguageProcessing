{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35fc4f2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchtext\n",
    "import numpy as np\n",
    "from torchnlp import *\n",
    "train_dataset,test_dataset,classes,vocab = load_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d7d470a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def char_tokenizer(words):\n",
    "    return list(words)\n",
    "\n",
    "counter = collections.Counter()\n",
    "for (label, line) in train_dataset:\n",
    "    counter.update(char_tokenizer(line))\n",
    "vocab = torchtext.vocab.vocab(counter)\n",
    "\n",
    "vocab_size = len(vocab)\n",
    "print(f\"Vocabulary size = {vocab_size}\")\n",
    "print(f\"Encoding of 'a' is {vocab.get_stoi() ['a']}\")\n",
    "print(f\"Character with code 13 is {vocab.get_itos()[13]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44e989b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def enc(x):\n",
    "    return torch.LongTensor(encode(x,voc=vocab, tokenizer=char_tokenizer))\n",
    "\n",
    "enc(train_dataset[0][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c3b9c8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "nchars = 100\n",
    "\n",
    "def get_batch(s,nchars=nchars):\n",
    "    ins = torch.zeros(len(s)-nchars,nchars,dtype=torch.long,device=device)\n",
    "    outs = torch.zeros(len(s)-nchars,nchars,dtype=torch.long,device=device)\n",
    "    for i in range(len(s)-nchars):\n",
    "        ins[i] = enc(s[i:i+nchars])\n",
    "        outs[i] = enc(s[i+1:i+nchars+1])\n",
    "    return ins,outs\n",
    "\n",
    "get_batch(train_dataset[0][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25966437",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTMGenerator(torch.nn.Module):\n",
    "    def __init__(self, vocab_size, hidden_dim):\n",
    "        super().__init__()\n",
    "        self.rnn = torch.nn.LSTM(vocab_size,hidden_dim,batch_first=True)\n",
    "        self.fc = torch.nn.Linear(hidden_dim, vocab_size)\n",
    "    \n",
    "    def forward(self, x, s=None):\n",
    "        x = torch.nn.functional.one_hot(x,vocab_size).to(torch.float32)\n",
    "        x,s = self.rnn(x,s)\n",
    "        return self.fc(x),s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94e28276",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate(net,size=100,start='today '):\n",
    "    chars = list(start)\n",
    "    out, s = net(enc(chars).view(1,-1).to(device))\n",
    "    for i in range(size):\n",
    "        nc = torch.argmax(out[0][-1])\n",
    "        chars.append(vocab.get_itos()[nc])\n",
    "        out,s = net(nc.view(1,-1),s)\n",
    "    return ''.join(chars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee9088e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "net = LSTMGenerator(vocab_size,64).to(device)\n",
    "\n",
    "samples_to_train = 10000\n",
    "optimizer = torch.optim.Adam(net.parameters(),0.01)\n",
    "loss_fn = torch.nn.CrossEntropyLoss()\n",
    "net.train()\n",
    "for i,x in enumerate(train_dataset):\n",
    "    # x[0] is class label, x[1] is text\n",
    "    if len(x[1])-nchars<10:\n",
    "        continue\n",
    "    samples_to_train-=1\n",
    "    if not samples_to_train: break\n",
    "    text_in, text_out = get_batch(x[1])\n",
    "    optimizer.zero_grad()\n",
    "    out,s = net(text_in)\n",
    "    loss = torch.nn.functional.cross_entropy(out.view(-1,vocab_size),text_out.flatten()) #cross_entropy(out,labels)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    if i%1000==0:\n",
    "        print(f\"Current loss = {loss.item()}\")\n",
    "        print(generate(net))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e2b6423",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_soft(net,size=100,start='today', temperature=1.0):\n",
    "    chars = list(start)\n",
    "    out,s = net(enc(chars).view(1,-1).to(device))\n",
    "    for i in range(size):\n",
    "        out_dist = out[0][1].div(temperature).exp()\n",
    "        nc = torch.multinomial(out_dist,1)[0]\n",
    "        chars.append(vocab.get_itos()[nc])\n",
    "        out,s = net(nc.view(1,-1),s)\n",
    "    return ''.join(chars)\n",
    "\n",
    "for i in [0.3,0.8,1.0,1.3,1.8]:\n",
    "    print(f\"--- Temperature = {i}\\n{generate_soft(net,size=300,start='Today ',temperature=i)}\\n\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
